name: Continuous Deployment

on:
  push:
    branches: [ main ]
    tags:
      - 'v*.*.*'

env:
  REGISTRY: ghcr.io
  FRONTEND_IMAGE_NAME: ${{ github.repository }}/frontend
  BACKEND_IMAGE_NAME: ${{ github.repository }}/backend

jobs:
  build-and-push-frontend:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20.x'
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json
    
    - name: Install dependencies
      working-directory: frontend
      run: npm ci
    
    - name: Run tests
      working-directory: frontend
      run: npm run test:coverage
      env:
        CI: true
    
    - name: Build application
      working-directory: frontend
      run: npm run build
    
    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.FRONTEND_IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=semver,pattern={{version}}
          type=semver,pattern={{major}}.{{minor}}
          type=sha,prefix={{branch}}-
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: ./frontend
        file: ./frontend/Dockerfile
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  build-and-push-backend:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up JDK 17
      uses: actions/setup-java@v4
      with:
        java-version: '17'
        distribution: 'temurin'
        cache: 'maven'
    
    - name: Build and test with Maven
      working-directory: backend
      run: ./mvnw clean package
    
    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.BACKEND_IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=semver,pattern={{version}}
          type=semver,pattern={{major}}.{{minor}}
          type=sha,prefix={{branch}}-
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: ./backend
        file: ./backend/Dockerfile
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  deploy:
    runs-on: ubuntu-latest
    needs: [build-and-push-frontend, build-and-push-backend]
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Verify secrets are configured
      run: |
        if [ -z "${{ secrets.AWS_ACCESS_KEY_ID }}" ]; then
          echo "ERROR: AWS_ACCESS_KEY_ID secret is not configured"
          exit 1
        fi
        if [ -z "${{ secrets.AWS_SECRET_ACCESS_KEY }}" ]; then
          echo "ERROR: AWS_SECRET_ACCESS_KEY secret is not configured"
          exit 1
        fi
        if [ -z "${{ secrets.AWS_REGION }}" ]; then
          echo "ERROR: AWS_REGION secret is not configured"
          exit 1
        fi
        if [ -z "${{ secrets.EC2_INSTANCE_ID }}" ]; then
          echo "ERROR: EC2_INSTANCE_ID secret is not configured"
          exit 1
        fi
        echo "All required secrets are configured"
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_REGION }}
    
    - name: Create deployment package
      run: |
        mkdir -p deploy
        cp docker-compose.deploy.yml deploy/docker-compose.yml
        
        # Create .env file
        cat > deploy/.env << 'ENVFILE'
        REDIS_PASSWORD=${{ secrets.REDIS_PASSWORD }}
        CORS_ALLOWED_ORIGINS=${{ secrets.CORS_ALLOWED_ORIGINS }}
        WEBSOCKET_ALLOWED_ORIGINS=${{ secrets.WEBSOCKET_ALLOWED_ORIGINS }}
        REACT_APP_API_URL=${{ secrets.REACT_APP_API_URL }}
        REACT_APP_WS_URL=${{ secrets.REACT_APP_WS_URL }}
        ENVFILE
        
        # Create deployment script
        cat > deploy/deploy.sh << 'DEPLOYEOF'
        #!/bin/bash
        set -e
        
        cd /home/ec2-user/tictactoe || cd /home/ubuntu/tictactoe || exit 1
        
        echo "=============================================="
        echo "Starting deployment process..."
        echo "=============================================="
        
        # Create directory if it doesn't exist
        mkdir -p /home/ec2-user/tictactoe 2>/dev/null || mkdir -p /home/ubuntu/tictactoe
        
        # Login to GitHub Container Registry
        echo "Logging into GitHub Container Registry..."
        echo "$GITHUB_TOKEN" | docker login ghcr.io -u "$GITHUB_ACTOR" --password-stdin
        
        # Pull latest images
        echo "Pulling latest images..."
        docker-compose pull
        
        # Stop existing containers
        echo "Stopping existing containers..."
        docker-compose down || true
        
        # Start new containers
        echo "Starting new containers..."
        docker-compose up -d
        
        echo ""
        echo "Waiting for services to start..."
        sleep 30
        
        echo ""
        echo "=============================================="
        echo "Service Status:"
        echo "=============================================="
        docker-compose ps
        echo "=============================================="
        
        # Cleanup old images
        echo ""
        echo "Cleaning up old images..."
        docker image prune -f
        
        echo ""
        echo "Deployment completed!"
        DEPLOYEOF
        
        chmod +x deploy/deploy.sh
    
    - name: Copy files to EC2 via S3
      run: |
        # Create a unique deployment ID
        DEPLOY_ID="${{ github.sha }}-$(date +%s)"
        S3_BUCKET="tictactoe-deployments-${{ secrets.AWS_REGION }}"
        
        # Create S3 bucket if it doesn't exist
        if ! aws s3 ls "s3://${S3_BUCKET}" 2>/dev/null; then
          echo "Creating S3 bucket: ${S3_BUCKET}"
          aws s3 mb "s3://${S3_BUCKET}" --region "${{ secrets.AWS_REGION }}"
          
          # Enable versioning for safety
          aws s3api put-bucket-versioning \
            --bucket "${S3_BUCKET}" \
            --versioning-configuration Status=Enabled
          
          # Set lifecycle policy to delete old deployments after 7 days
          cat > /tmp/lifecycle.json << 'EOF'
        {
          "Rules": [
            {
              "Id": "DeleteOldDeployments",
              "Status": "Enabled",
              "Prefix": "",
              "Expiration": {
                "Days": 7
              }
            }
          ]
        }
        EOF
          aws s3api put-bucket-lifecycle-configuration \
            --bucket "${S3_BUCKET}" \
            --lifecycle-configuration file:///tmp/lifecycle.json
        fi
        
        # Upload deployment files to S3
        echo "Uploading deployment files to S3..."
        aws s3 cp deploy/docker-compose.yml "s3://${S3_BUCKET}/${DEPLOY_ID}/docker-compose.yml"
        aws s3 cp deploy/.env "s3://${S3_BUCKET}/${DEPLOY_ID}/.env"
        aws s3 cp deploy/deploy.sh "s3://${S3_BUCKET}/${DEPLOY_ID}/deploy.sh"
        
        echo "DEPLOY_ID=${DEPLOY_ID}" >> $GITHUB_ENV
        echo "S3_BUCKET=${S3_BUCKET}" >> $GITHUB_ENV
    
    - name: Deploy to EC2 via SSM
      run: |
        echo "Starting deployment on EC2..."
        
        # Create simple deployment script that downloads from S3
        DOWNLOAD_AND_DEPLOY='
        #!/bin/bash
        set -e
        
        # Determine home directory
        if [ -d "/home/ec2-user" ]; then
          HOME_DIR="/home/ec2-user"
        else
          HOME_DIR="/home/ubuntu"
        fi
        
        # Create directory
        mkdir -p $HOME_DIR/tictactoe
        cd $HOME_DIR/tictactoe
        
        # Download files from S3
        aws s3 cp s3://'"$S3_BUCKET"'/'"$DEPLOY_ID"'/docker-compose.yml ./docker-compose.yml
        aws s3 cp s3://'"$S3_BUCKET"'/'"$DEPLOY_ID"'/.env ./.env
        aws s3 cp s3://'"$S3_BUCKET"'/'"$DEPLOY_ID"'/deploy.sh ./deploy.sh
        chmod +x ./deploy.sh
        
        # Set environment variables
        export GITHUB_TOKEN="'"${{ secrets.GITHUB_TOKEN }}"'"
        export GITHUB_ACTOR="'"${{ github.actor }}"'"
        
        # Run deployment
        ./deploy.sh
        '
        
        # Send deployment command via SSM
        COMMAND_ID=$(aws ssm send-command \
          --instance-ids "${{ secrets.EC2_INSTANCE_ID }}" \
          --document-name "AWS-RunShellScript" \
          --parameters commands="$DOWNLOAD_AND_DEPLOY" \
          --output text \
          --query 'Command.CommandId')
        
        echo "Command ID: $COMMAND_ID"
        echo "Waiting for command to complete..."
        
        # Wait for command to complete
        for i in {1..60}; do
          STATUS=$(aws ssm get-command-invocation \
            --command-id "$COMMAND_ID" \
            --instance-id "${{ secrets.EC2_INSTANCE_ID }}" \
            --query 'Status' \
            --output text)
          
          echo "Status: $STATUS"
          
          if [ "$STATUS" = "Success" ]; then
            echo "Deployment successful!"
            
            # Get command output
            aws ssm get-command-invocation \
              --command-id "$COMMAND_ID" \
              --instance-id "${{ secrets.EC2_INSTANCE_ID }}" \
              --query 'StandardOutputContent' \
              --output text
            
            # Cleanup S3 files
            aws s3 rm "s3://${S3_BUCKET}/${DEPLOY_ID}/" --recursive
            
            exit 0
          elif [ "$STATUS" = "Failed" ]; then
            echo "Deployment failed!"
            
            # Get error output
            aws ssm get-command-invocation \
              --command-id "$COMMAND_ID" \
              --instance-id "${{ secrets.EC2_INSTANCE_ID }}" \
              --query 'StandardErrorContent' \
              --output text
            
            # Cleanup S3 files
            aws s3 rm "s3://${S3_BUCKET}/${DEPLOY_ID}/" --recursive
            
            exit 1
          fi
          
          sleep 10
        done
        
        echo "Deployment timed out"
        # Cleanup S3 files
        aws s3 rm "s3://${S3_BUCKET}/${DEPLOY_ID}/" --recursive
        exit 1
    
    - name: Deployment notification
      run: |
        echo "::notice::Successfully deployed version ${{ github.sha }} to production on EC2"
